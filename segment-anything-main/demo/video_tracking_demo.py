#!/usr/bin/env python
# -*- coding: UTF-8 -*-
"""
SAMè§†é¢‘åˆ†å‰²æ¼”ç¤º - è§†é¢‘ä¸­ç‰©ä½“çš„å®æ—¶åˆ†å‰²è·Ÿè¸ª
åº”ç”¨åœºæ™¯ï¼šè§†é¢‘ç›‘æ§ã€è¿åŠ¨åˆ†æã€è‡ªåŠ¨é©¾é©¶ã€è§†é¢‘ç¼–è¾‘
"""
import numpy as np
import matplotlib.pyplot as plt
import cv2
from segment_anything import sam_model_registry, SamPredictor
from common_tools import show_mask, show_points
import os
import time
import json

class VideoSegmentationTracker:
    def __init__(self, model_path="models/sam_vit_h_4b8939.pth", device="cpu"):
        self.sam_checkpoint = model_path
        self.model_type = "vit_h"
        self.device = device
        self.sam = None
        self.predictor = None
        self.tracking_history = []
        self.load_model()
    
    def load_model(self):
        """åŠ è½½SAMæ¨¡å‹"""
        print("æ­£åœ¨åŠ è½½è§†é¢‘åˆ†å‰²æ¨¡å‹...")
        self.sam = sam_model_registry[self.model_type](checkpoint=self.sam_checkpoint)
        self.sam.to(device=self.device)
        self.predictor = SamPredictor(self.sam)
        print("è§†é¢‘åˆ†å‰²æ¨¡å‹åŠ è½½å®Œæˆï¼")
    
    def track_object_in_images(self, image_paths, initial_point, output_dir="video_tracking_results"):
        """
        åœ¨å›¾åƒåºåˆ—ä¸­è·Ÿè¸ªç‰©ä½“
        æ¨¡æ‹Ÿè§†é¢‘è·Ÿè¸ªçš„æ•ˆæœ
        """
        os.makedirs(output_dir, exist_ok=True)
        tracking_data = []
        
        print(f"å¼€å§‹è·Ÿè¸ªç‰©ä½“ï¼Œå…± {len(image_paths)} å¸§å›¾åƒ")
        
        for frame_idx, image_path in enumerate(image_paths):
            if not os.path.exists(image_path):
                print(f"è­¦å‘Šï¼šå›¾åƒ {image_path} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue
                
            print(f"å¤„ç†ç¬¬ {frame_idx + 1}/{len(image_paths)} å¸§: {image_path}")
            
            # è¯»å–å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                print(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
                continue
                
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # è®¾ç½®å›¾åƒ
            start_time = time.time()
            self.predictor.set_image(image_rgb)
            
            # ä½¿ç”¨ç‚¹è¿›è¡Œåˆ†å‰²
            if frame_idx == 0:
                # ç¬¬ä¸€å¸§ä½¿ç”¨åˆå§‹ç‚¹
                current_point = initial_point
            else:
                # åç»­å¸§ä½¿ç”¨å‰ä¸€å¸§çš„è´¨å¿ƒä½œä¸ºè·Ÿè¸ªç‚¹
                if tracking_data:
                    last_mask = tracking_data[-1]['mask']
                    current_point = self.calculate_centroid(last_mask)
                else:
                    current_point = initial_point
            
            input_point = np.array([current_point])
            input_label = np.array([1])
            
            # é¢„æµ‹æ©ç 
            masks, scores, logits = self.predictor.predict(
                point_coords=input_point,
                point_labels=input_label,
                multimask_output=True,
            )
            
            # é€‰æ‹©æœ€ä½³æ©ç 
            best_mask_idx = np.argmax(scores)
            best_mask = masks[best_mask_idx]
            best_score = scores[best_mask_idx]
            
            processing_time = time.time() - start_time
            
            # è®¡ç®—ç‰©ä½“å±æ€§
            bbox = self.calculate_bbox(best_mask)
            area = np.sum(best_mask)
            centroid = self.calculate_centroid(best_mask)
            
            # ä¿å­˜è·Ÿè¸ªæ•°æ®
            frame_data = {
                'frame_idx': frame_idx,
                'image_path': image_path,
                'point': current_point,
                'mask': best_mask,
                'score': float(best_score),
                'bbox': bbox,
                'area': int(area),
                'centroid': centroid,
                'processing_time': processing_time
            }
            tracking_data.append(frame_data)
            
            # ä¿å­˜å¯è§†åŒ–ç»“æœ
            self.save_tracking_frame(image_rgb, best_mask, current_point, 
                                   frame_idx, best_score, output_dir)
            
            print(f"  åˆ†å‰²å¾—åˆ†: {best_score:.3f}, å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        
        # ä¿å­˜è·Ÿè¸ªæŠ¥å‘Š
        self.save_tracking_report(tracking_data, output_dir)
        return tracking_data
    
    def calculate_centroid(self, mask):
        """è®¡ç®—æ©ç çš„è´¨å¿ƒ"""
        y_indices, x_indices = np.where(mask)
        if len(y_indices) > 0:
            centroid_x = int(np.mean(x_indices))
            centroid_y = int(np.mean(y_indices))
            return [centroid_x, centroid_y]
        return [0, 0]
    
    def calculate_bbox(self, mask):
        """è®¡ç®—æ©ç çš„è¾¹ç•Œæ¡†"""
        y_indices, x_indices = np.where(mask)
        if len(y_indices) > 0:
            return [int(np.min(x_indices)), int(np.min(y_indices)),
                   int(np.max(x_indices)), int(np.max(y_indices))]
        return [0, 0, 0, 0]
    
    def save_tracking_frame(self, image, mask, point, frame_idx, score, output_dir):
        """ä¿å­˜å•å¸§è·Ÿè¸ªç»“æœ"""
        plt.figure(figsize=(12, 8))
        plt.imshow(image)
        show_mask(mask, plt.gca())
        show_points(np.array([point]), np.array([1]), plt.gca())
        
        # æ·»åŠ ä¿¡æ¯æ–‡æœ¬
        plt.text(10, 30, f"Frame: {frame_idx + 1}", fontsize=12, color='white', 
                weight='bold', bbox=dict(boxstyle="round,pad=0.3", facecolor='black', alpha=0.7))
        plt.text(10, 60, f"Score: {score:.3f}", fontsize=12, color='white', 
                weight='bold', bbox=dict(boxstyle="round,pad=0.3", facecolor='black', alpha=0.7))
        
        plt.title(f"Object Tracking - Frame {frame_idx + 1}")
        plt.axis('off')
        
        filename = f"frame_{frame_idx:04d}_tracking.png"
        plt.savefig(os.path.join(output_dir, filename), dpi=150, bbox_inches='tight')
        plt.close()
    
    def save_tracking_report(self, tracking_data, output_dir):
        """ä¿å­˜è·Ÿè¸ªåˆ†ææŠ¥å‘Š"""
        if not tracking_data:
            return
        
        # å‡†å¤‡æŠ¥å‘Šæ•°æ®
        report_data = {
            'total_frames': len(tracking_data),
            'average_score': float(np.mean([d['score'] for d in tracking_data])),
            'average_area': float(np.mean([d['area'] for d in tracking_data])),
            'average_processing_time': float(np.mean([d['processing_time'] for d in tracking_data])),
            'frames': []
        }
        
        for data in tracking_data:
            frame_info = {
                'frame_idx': data['frame_idx'],
                'image_path': data['image_path'],
                'point': data['point'],
                'score': data['score'],
                'bbox': data['bbox'],
                'area': data['area'],
                'centroid': data['centroid'],
                'processing_time': data['processing_time']
            }
            report_data['frames'].append(frame_info)
        
        # ä¿å­˜JSONæŠ¥å‘Š
        report_file = os.path.join(output_dir, "tracking_report.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆè·Ÿè¸ªè½¨è¿¹å›¾
        self.plot_tracking_trajectory(tracking_data, output_dir)
        
        print(f"è·Ÿè¸ªæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    def plot_tracking_trajectory(self, tracking_data, output_dir):
        """ç»˜åˆ¶è·Ÿè¸ªè½¨è¿¹å›¾"""
        if len(tracking_data) < 2:
            return
        
        # æå–è½¨è¿¹æ•°æ®
        centroids = [data['centroid'] for data in tracking_data]
        scores = [data['score'] for data in tracking_data]
        areas = [data['area'] for data in tracking_data]
        frames = [data['frame_idx'] for data in tracking_data]
        
        x_coords = [c[0] for c in centroids]
        y_coords = [c[1] for c in centroids]
        
        # åˆ›å»ºè½¨è¿¹å›¾
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        # è½¨è¿¹å›¾
        ax1.plot(x_coords, y_coords, 'b-o', linewidth=2, markersize=4)
        ax1.set_xlabel('X åæ ‡')
        ax1.set_ylabel('Y åæ ‡')
        ax1.set_title('ç‰©ä½“è·Ÿè¸ªè½¨è¿¹')
        ax1.grid(True, alpha=0.3)
        
        # åˆ†å‰²å¾—åˆ†éšæ—¶é—´å˜åŒ–
        ax2.plot(frames, scores, 'g-o', linewidth=2)
        ax2.set_xlabel('å¸§æ•°')
        ax2.set_ylabel('åˆ†å‰²å¾—åˆ†')
        ax2.set_title('åˆ†å‰²è´¨é‡éšæ—¶é—´å˜åŒ–')
        ax2.grid(True, alpha=0.3)
        
        # ç‰©ä½“é¢ç§¯éšæ—¶é—´å˜åŒ–
        ax3.plot(frames, areas, 'r-o', linewidth=2)
        ax3.set_xlabel('å¸§æ•°')
        ax3.set_ylabel('ç‰©ä½“é¢ç§¯ (åƒç´ )')
        ax3.set_title('ç‰©ä½“å¤§å°éšæ—¶é—´å˜åŒ–')
        ax3.grid(True, alpha=0.3)
        
        # Xåæ ‡éšæ—¶é—´å˜åŒ–
        ax4.plot(frames, x_coords, 'c-o', linewidth=2, label='Xåæ ‡')
        ax4.plot(frames, y_coords, 'm-o', linewidth=2, label='Yåæ ‡')
        ax4.set_xlabel('å¸§æ•°')
        ax4.set_ylabel('åæ ‡')
        ax4.set_title('ç‰©ä½“ä½ç½®éšæ—¶é—´å˜åŒ–')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'tracking_analysis.png'), dpi=150, bbox_inches='tight')
        plt.show()

def demo_multi_object_tracking():
    """æ¼”ç¤ºå¤šç‰©ä½“è·Ÿè¸ª"""
    tracker = VideoSegmentationTracker()
    
    # æ¨¡æ‹Ÿè§†é¢‘åºåˆ—ï¼ˆä½¿ç”¨å¤šå¼ å›¾åƒï¼‰
    image_sequence = [
        'images/truck.jpg',
        'images/dog.jpg',
        'images/groceries.jpg'
    ]
    
    # æ£€æŸ¥å›¾åƒæ˜¯å¦å­˜åœ¨
    available_images = [img for img in image_sequence if os.path.exists(img)]
    if not available_images:
        print("è­¦å‘Šï¼šæ‰¾ä¸åˆ°æ¼”ç¤ºå›¾åƒï¼Œè¯·ç¡®ä¿imagesæ–‡ä»¶å¤¹ä¸­æœ‰å›¾åƒæ–‡ä»¶")
        return
    
    print(f"\n=== å¤šç‰©ä½“è·Ÿè¸ªæ¼”ç¤º ===")
    print(f"ä½¿ç”¨ {len(available_images)} å¼ å›¾åƒæ¨¡æ‹Ÿè§†é¢‘è·Ÿè¸ª")
    
    # å®šä¹‰åˆå§‹è·Ÿè¸ªç‚¹
    initial_point = [400, 300]  # å›¾åƒä¸­å¿ƒé™„è¿‘
    
    # æ‰§è¡Œè·Ÿè¸ª
    tracking_results = tracker.track_object_in_images(
        available_images, 
        initial_point,
        "video_tracking_demo"
    )
    
    # è¾“å‡ºè·Ÿè¸ªç»Ÿè®¡
    if tracking_results:
        total_frames = len(tracking_results)
        avg_score = np.mean([r['score'] for r in tracking_results])
        avg_area = np.mean([r['area'] for r in tracking_results])
        
        print(f"\nğŸ“Š è·Ÿè¸ªç»Ÿè®¡:")
        print(f"  æ€»å¸§æ•°: {total_frames}")
        print(f"  å¹³å‡åˆ†å‰²å¾—åˆ†: {avg_score:.3f}")
        print(f"  å¹³å‡ç‰©ä½“é¢ç§¯: {avg_area:.0f} åƒç´ ")
        
        # æ˜¾ç¤ºè½¨è¿¹å˜åŒ–
        centroids = [r['centroid'] for r in tracking_results]
        print(f"  è½¨è¿¹ç‚¹: {centroids}")

def demo_object_motion_analysis():
    """æ¼”ç¤ºç‰©ä½“è¿åŠ¨åˆ†æ"""
    print(f"\n=== ç‰©ä½“è¿åŠ¨åˆ†ææ¼”ç¤º ===")
    
    # æ¨¡æ‹Ÿè¿åŠ¨æ•°æ®ï¼ˆå®é™…åº”ç”¨ä¸­ä»è§†é¢‘è·Ÿè¸ªè·å¾—ï¼‰
    motion_data = [
        {'frame': 0, 'x': 100, 'y': 100, 'area': 1500},
        {'frame': 1, 'x': 120, 'y': 105, 'area': 1520},
        {'frame': 2, 'x': 140, 'y': 110, 'area': 1480},
        {'frame': 3, 'x': 160, 'y': 120, 'area': 1550},
        {'frame': 4, 'x': 185, 'y': 125, 'area': 1600},
    ]
    
    # åˆ†æè¿åŠ¨ç‰¹å¾
    print("åˆ†æç‰©ä½“è¿åŠ¨ç‰¹å¾:")
    
    for i in range(1, len(motion_data)):
        prev = motion_data[i-1]
        curr = motion_data[i]
        
        # è®¡ç®—ä½ç§»
        dx = curr['x'] - prev['x']
        dy = curr['y'] - prev['y']
        displacement = np.sqrt(dx**2 + dy**2)
        
        # è®¡ç®—é€Ÿåº¦ï¼ˆåƒç´ /å¸§ï¼‰
        velocity = displacement
        
        # è®¡ç®—é¢ç§¯å˜åŒ–ç‡
        area_change = (curr['area'] - prev['area']) / prev['area'] * 100
        
        print(f"  å¸§ {prev['frame']} -> {curr['frame']}:")
        print(f"    ä½ç§»: {displacement:.2f} åƒç´ ")
        print(f"    é€Ÿåº¦: {velocity:.2f} åƒç´ /å¸§") 
        print(f"    é¢ç§¯å˜åŒ–: {area_change:+.1f}%")
    
    # ç»˜åˆ¶è¿åŠ¨è½¨è¿¹
    x_coords = [d['x'] for d in motion_data]
    y_coords = [d['y'] for d in motion_data]
    areas = [d['area'] for d in motion_data]
    frames = [d['frame'] for d in motion_data]
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # è¿åŠ¨è½¨è¿¹
    ax1.plot(x_coords, y_coords, 'bo-', linewidth=2, markersize=8)
    for i, (x, y, frame) in enumerate(zip(x_coords, y_coords, frames)):
        ax1.annotate(f'F{frame}', (x, y), xytext=(5, 5), textcoords='offset points')
    ax1.set_xlabel('X åæ ‡')
    ax1.set_ylabel('Y åæ ‡')
    ax1.set_title('ç‰©ä½“è¿åŠ¨è½¨è¿¹')
    ax1.grid(True, alpha=0.3)
    
    # é¢ç§¯å˜åŒ–
    ax2.plot(frames, areas, 'ro-', linewidth=2, markersize=8)
    ax2.set_xlabel('å¸§æ•°')
    ax2.set_ylabel('ç‰©ä½“é¢ç§¯')
    ax2.set_title('ç‰©ä½“å¤§å°å˜åŒ–')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('motion_analysis_demo.png', dpi=150, bbox_inches='tight')
    plt.show()

if __name__ == '__main__':
    print("=== SAMè§†é¢‘åˆ†å‰²ä¸è·Ÿè¸ªæ¼”ç¤º ===")
    
    try:
        # æ¼”ç¤ºå¤šç‰©ä½“è·Ÿè¸ª
        demo_multi_object_tracking()
        
        # æ¼”ç¤ºè¿åŠ¨åˆ†æ
        demo_object_motion_analysis()
        
        print("\nâœ… è§†é¢‘åˆ†å‰²æ¼”ç¤ºå®Œæˆï¼")
        print("ğŸ’¡ åœ¨å®é™…è§†é¢‘åº”ç”¨ä¸­ï¼Œå»ºè®®:")
        print("   1. ä½¿ç”¨è¿ç»­çš„è§†é¢‘å¸§è€Œéé™æ€å›¾åƒ")
        print("   2. å®ç°æ›´æ™ºèƒ½çš„è·Ÿè¸ªç‚¹æ›´æ–°ç­–ç•¥")
        print("   3. æ·»åŠ å¤šç›®æ ‡è·Ÿè¸ªåŠŸèƒ½")
        print("   4. ä¼˜åŒ–å¤„ç†é€Ÿåº¦ä»¥å®ç°å®æ—¶è·Ÿè¸ª")
        print("   5. é›†æˆKalmanæ»¤æ³¢ç­‰é¢„æµ‹ç®—æ³•")
        
    except Exception as e:
        print(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å’Œå›¾åƒæ–‡ä»¶å­˜åœ¨")
