#!/usr/bin/env python
# -*- coding: UTF-8 -*-
"""
SAMäº¤äº’å¼æ ‡æ³¨å·¥å…· - ç”¨äºå¿«é€Ÿåˆ›å»ºè®­ç»ƒæ•°æ®é›†
åº”ç”¨åœºæ™¯ï¼šæ•°æ®æ ‡æ³¨ã€åŠè‡ªåŠ¨æ ‡æ³¨ã€æ ‡æ³¨è´¨é‡æ§åˆ¶ã€æ•°æ®é›†åˆ›å»º
"""
import numpy as np
import matplotlib.pyplot as plt
import cv2
from segment_anything import sam_model_registry, SamPredictor
from common_tools import show_mask, show_points, show_box
import json
import os
from datetime import datetime
import tkinter as tk
from tkinter import ttk, filedialog, messagebox

class InteractiveAnnotationTool:
    def __init__(self, model_path="models/sam_vit_h_4b8939.pth", device="cpu"):
        self.sam_checkpoint = model_path
        self.model_type = "vit_h"
        self.device = device
        self.sam = None
        self.predictor = None
        
        # æ ‡æ³¨çŠ¶æ€
        self.current_image = None
        self.current_image_path = None
        self.current_masks = []
        self.annotation_points = []
        self.annotation_labels = []
        self.annotation_history = []
        self.current_class = "object"
        
        # ç±»åˆ«å®šä¹‰
        self.classes = ["background", "object", "person", "vehicle", "animal", "building"]
        self.class_colors = {
            "background": [128, 128, 128],
            "object": [255, 0, 0],
            "person": [0, 255, 0], 
            "vehicle": [0, 0, 255],
            "animal": [255, 255, 0],
            "building": [255, 0, 255]
        }
        
        self.load_model()
    
    def load_model(self):
        """åŠ è½½SAMæ¨¡å‹"""
        print("æ­£åœ¨åŠ è½½äº¤äº’å¼æ ‡æ³¨æ¨¡å‹...")
        self.sam = sam_model_registry[self.model_type](checkpoint=self.sam_checkpoint)
        self.sam.to(device=self.device)
        self.predictor = SamPredictor(self.sam)
        print("äº¤äº’å¼æ ‡æ³¨æ¨¡å‹åŠ è½½å®Œæˆï¼")
    
    def set_image(self, image_path):
        """è®¾ç½®å½“å‰æ ‡æ³¨å›¾åƒ"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        
        self.current_image_path = image_path
        self.current_image = cv2.imread(image_path)
        self.current_image = cv2.cvtColor(self.current_image, cv2.COLOR_BGR2RGB)
        
        print(f"è®¾ç½®å›¾åƒ: {image_path}, å°ºå¯¸: {self.current_image.shape}")
        self.predictor.set_image(self.current_image)
        
        # é‡ç½®æ ‡æ³¨çŠ¶æ€
        self.current_masks = []
        self.annotation_points = []
        self.annotation_labels = []
        self.annotation_history = []
    
    def add_positive_point(self, x, y):
        """æ·»åŠ æ­£å‘ç‚¹ï¼ˆå‰æ™¯ç‚¹ï¼‰"""
        self.annotation_points.append([x, y])
        self.annotation_labels.append(1)
        return self.update_mask()
    
    def add_negative_point(self, x, y):
        """æ·»åŠ è´Ÿå‘ç‚¹ï¼ˆèƒŒæ™¯ç‚¹ï¼‰"""
        self.annotation_points.append([x, y])
        self.annotation_labels.append(0)
        return self.update_mask()
    
    def add_bounding_box(self, x1, y1, x2, y2):
        """æ·»åŠ è¾¹ç•Œæ¡†"""
        bbox = np.array([x1, y1, x2, y2])
        
        point_coords = np.array(self.annotation_points) if self.annotation_points else None
        point_labels = np.array(self.annotation_labels) if self.annotation_labels else None
        
        masks, scores, logits = self.predictor.predict(
            point_coords=point_coords,
            point_labels=point_labels,
            box=bbox[None, :],
            multimask_output=True,
        )
        
        # é€‰æ‹©æœ€ä½³æ©ç 
        best_mask_idx = np.argmax(scores)
        best_mask = masks[best_mask_idx]
        best_score = scores[best_mask_idx]
        
        return best_mask, best_score
    
    def update_mask(self):
        """æ›´æ–°å½“å‰æ©ç """
        if not self.annotation_points:
            return None, 0
        
        point_coords = np.array(self.annotation_points)
        point_labels = np.array(self.annotation_labels)
        
        masks, scores, logits = self.predictor.predict(
            point_coords=point_coords,
            point_labels=point_labels,
            multimask_output=True,
        )
        
        # é€‰æ‹©æœ€ä½³æ©ç 
        best_mask_idx = np.argmax(scores)
        best_mask = masks[best_mask_idx]
        best_score = scores[best_mask_idx]
        
        return best_mask, best_score
    
    def undo_last_point(self):
        """æ’¤é”€æœ€åä¸€ä¸ªç‚¹"""
        if self.annotation_points:
            self.annotation_points.pop()
            self.annotation_labels.pop()
            return self.update_mask()
        return None, 0
    
    def clear_all_points(self):
        """æ¸…é™¤æ‰€æœ‰ç‚¹"""
        self.annotation_points = []
        self.annotation_labels = []
        return None, 0
    
    def save_annotation(self, mask, class_name, output_dir):
        """ä¿å­˜å½“å‰æ ‡æ³¨"""
        if self.current_image is None or mask is None:
            return False
        
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆå”¯ä¸€çš„æ ‡æ³¨ID
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        annotation_id = f"{os.path.basename(self.current_image_path).split('.')[0]}_{timestamp}"
        
        # ä¿å­˜æ©ç 
        mask_file = os.path.join(output_dir, f"{annotation_id}_mask.png")
        cv2.imwrite(mask_file, (mask * 255).astype(np.uint8))
        
        # åˆ›å»ºæ ‡æ³¨è®°å½•
        annotation_record = {
            'annotation_id': annotation_id,
            'image_path': self.current_image_path,
            'class_name': class_name,
            'mask_file': mask_file,
            'points': self.annotation_points.copy(),
            'labels': self.annotation_labels.copy(),
            'timestamp': timestamp,
            'image_size': self.current_image.shape[:2],
            'mask_area': int(np.sum(mask))
        }
        
        # ä¿å­˜æ ‡æ³¨è®°å½•
        record_file = os.path.join(output_dir, f"{annotation_id}_annotation.json")
        with open(record_file, 'w', encoding='utf-8') as f:
            json.dump(annotation_record, f, indent=2, ensure_ascii=False)
        
        # æ·»åŠ åˆ°å†å²è®°å½•
        self.annotation_history.append(annotation_record)
        
        print(f"æ ‡æ³¨å·²ä¿å­˜: {annotation_id}")
        return True
    
    def load_annotation_project(self, project_dir):
        """åŠ è½½æ ‡æ³¨é¡¹ç›®"""
        if not os.path.exists(project_dir):
            return []
        
        annotations = []
        for file in os.listdir(project_dir):
            if file.endswith('_annotation.json'):
                try:
                    with open(os.path.join(project_dir, file), 'r', encoding='utf-8') as f:
                        annotation = json.load(f)
                        annotations.append(annotation)
                except Exception as e:
                    print(f"åŠ è½½æ ‡æ³¨æ–‡ä»¶å¤±è´¥ {file}: {e}")
        
        return sorted(annotations, key=lambda x: x['timestamp'])
    
    def create_annotation_statistics(self, annotations):
        """åˆ›å»ºæ ‡æ³¨ç»Ÿè®¡"""
        if not annotations:
            return {}
        
        stats = {
            'total_annotations': len(annotations),
            'class_distribution': {},
            'total_mask_area': 0,
            'average_mask_area': 0,
            'images_annotated': len(set(ann['image_path'] for ann in annotations))
        }
        
        # ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡
        for annotation in annotations:
            class_name = annotation['class_name']
            mask_area = annotation['mask_area']
            
            if class_name not in stats['class_distribution']:
                stats['class_distribution'][class_name] = {
                    'count': 0,
                    'total_area': 0,
                    'average_area': 0
                }
            
            stats['class_distribution'][class_name]['count'] += 1
            stats['class_distribution'][class_name]['total_area'] += mask_area
            stats['total_mask_area'] += mask_area
        
        # è®¡ç®—å¹³å‡å€¼
        stats['average_mask_area'] = stats['total_mask_area'] / stats['total_annotations']
        
        for class_name in stats['class_distribution']:
            class_stats = stats['class_distribution'][class_name]
            class_stats['average_area'] = class_stats['total_area'] / class_stats['count']
        
        return stats
    
    def visualize_annotation_progress(self, annotations, output_dir):
        """å¯è§†åŒ–æ ‡æ³¨è¿›åº¦"""
        if not annotations:
            print("æ²¡æœ‰æ ‡æ³¨æ•°æ®å¯è§†åŒ–")
            return
        
        stats = self.create_annotation_statistics(annotations)
        
        # åˆ›å»ºè¿›åº¦å›¾è¡¨
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        # ç±»åˆ«åˆ†å¸ƒ
        class_names = list(stats['class_distribution'].keys())
        class_counts = [stats['class_distribution'][name]['count'] for name in class_names]
        
        ax1.pie(class_counts, labels=class_names, autopct='%1.1f%%', startangle=90)
        ax1.set_title('ç±»åˆ«åˆ†å¸ƒ')
        
        # é¢ç§¯åˆ†å¸ƒ
        class_areas = [stats['class_distribution'][name]['total_area'] for name in class_names]
        ax2.bar(class_names, class_areas, color=['red', 'green', 'blue', 'orange', 'purple'][:len(class_names)])
        ax2.set_title('ç±»åˆ«é¢ç§¯åˆ†å¸ƒ')
        ax2.set_ylabel('æ€»é¢ç§¯ (åƒç´ )')
        plt.setp(ax2.get_xticklabels(), rotation=45)
        
        # æ ‡æ³¨æ—¶é—´çº¿
        timestamps = [ann['timestamp'] for ann in annotations]
        cumulative_counts = list(range(1, len(annotations) + 1))
        ax3.plot(cumulative_counts, marker='o')
        ax3.set_title('æ ‡æ³¨è¿›åº¦æ—¶é—´çº¿')
        ax3.set_xlabel('æ ‡æ³¨é¡ºåº')
        ax3.set_ylabel('ç´¯è®¡æ ‡æ³¨æ•°é‡')
        ax3.grid(True, alpha=0.3)
        
        # å¹³å‡æ©ç å¤§å°
        mask_sizes = [ann['mask_area'] for ann in annotations]
        ax4.hist(mask_sizes, bins=20, alpha=0.7, color='skyblue')
        ax4.axvline(stats['average_mask_area'], color='red', linestyle='--', 
                   label=f'å¹³å‡å€¼: {stats["average_mask_area"]:.0f}')
        ax4.set_title('æ©ç é¢ç§¯åˆ†å¸ƒ')
        ax4.set_xlabel('é¢ç§¯ (åƒç´ )')
        ax4.set_ylabel('é¢‘æ¬¡')
        ax4.legend()
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'annotation_statistics.png'), dpi=150, bbox_inches='tight')
        plt.show()
        
        # è¾“å‡ºç»Ÿè®¡æ‘˜è¦
        print("\nğŸ“Š æ ‡æ³¨ç»Ÿè®¡æ‘˜è¦:")
        print(f"  æ€»æ ‡æ³¨æ•°: {stats['total_annotations']}")
        print(f"  æ ‡æ³¨å›¾åƒæ•°: {stats['images_annotated']}")
        print(f"  å¹³å‡æ©ç é¢ç§¯: {stats['average_mask_area']:.0f} åƒç´ ")
        print(f"  ç±»åˆ«åˆ†å¸ƒ:")
        for class_name, class_stats in stats['class_distribution'].items():
            print(f"    {class_name}: {class_stats['count']} ä¸ª (å¹³å‡é¢ç§¯: {class_stats['average_area']:.0f})")

def demo_interactive_annotation():
    """æ¼”ç¤ºäº¤äº’å¼æ ‡æ³¨åŠŸèƒ½"""
    tool = InteractiveAnnotationTool()
    
    print("\n=== äº¤äº’å¼æ ‡æ³¨å·¥å…·æ¼”ç¤º ===")
    
    # è®¾ç½®å›¾åƒ
    image_path = 'images/truck.jpg'
    if not os.path.exists(image_path):
        print(f"æ¼”ç¤ºå›¾åƒ {image_path} ä¸å­˜åœ¨")
        return
    
    tool.set_image(image_path)
    
    # æ¨¡æ‹Ÿæ ‡æ³¨è¿‡ç¨‹
    print("æ¨¡æ‹Ÿäº¤äº’å¼æ ‡æ³¨è¿‡ç¨‹...")
    
    # æ·»åŠ æ­£å‘ç‚¹
    mask1, score1 = tool.add_positive_point(400, 300)
    print(f"æ·»åŠ æ­£å‘ç‚¹ (400, 300), å¾—åˆ†: {score1:.3f}")
    
    # æ·»åŠ è´Ÿå‘ç‚¹
    mask2, score2 = tool.add_negative_point(100, 100)
    print(f"æ·»åŠ è´Ÿå‘ç‚¹ (100, 100), å¾—åˆ†: {score2:.3f}")
    
    # å†æ·»åŠ ä¸€ä¸ªæ­£å‘ç‚¹
    mask3, score3 = tool.add_positive_point(450, 350)
    print(f"æ·»åŠ æ­£å‘ç‚¹ (450, 350), å¾—åˆ†: {score3:.3f}")
    
    # å¯è§†åŒ–æ ‡æ³¨è¿‡ç¨‹
    if mask3 is not None:
        plt.figure(figsize=(15, 5))
        
        # åŸå›¾
        plt.subplot(1, 3, 1)
        plt.imshow(tool.current_image)
        plt.title("åŸå§‹å›¾åƒ")
        plt.axis('off')
        
        # æ ‡æ³¨ç‚¹
        plt.subplot(1, 3, 2)
        plt.imshow(tool.current_image)
        points = np.array(tool.annotation_points)
        labels = np.array(tool.annotation_labels)
        show_points(points, labels, plt.gca())
        plt.title("æ ‡æ³¨ç‚¹")
        plt.axis('off')
        
        # åˆ†å‰²ç»“æœ
        plt.subplot(1, 3, 3)
        plt.imshow(tool.current_image)
        show_mask(mask3, plt.gca())
        show_points(points, labels, plt.gca())
        plt.title(f"åˆ†å‰²ç»“æœ (å¾—åˆ†: {score3:.3f})")
        plt.axis('off')
        
        plt.tight_layout()
        plt.savefig('interactive_annotation_demo.png', dpi=150, bbox_inches='tight')
        plt.show()
    
    # ä¿å­˜æ ‡æ³¨
    output_dir = "annotation_project_demo"
    success = tool.save_annotation(mask3, "vehicle", output_dir)
    if success:
        print(f"æ ‡æ³¨å·²ä¿å­˜åˆ°: {output_dir}")
    
    # æµ‹è¯•æ’¤é”€åŠŸèƒ½
    print("\næµ‹è¯•æ’¤é”€åŠŸèƒ½...")
    mask_undo, score_undo = tool.undo_last_point()
    print(f"æ’¤é”€åå¾—åˆ†: {score_undo:.3f}")
    
    # æ¸…é™¤æ‰€æœ‰ç‚¹
    tool.clear_all_points()
    print("å·²æ¸…é™¤æ‰€æœ‰æ ‡æ³¨ç‚¹")

def demo_annotation_quality_control():
    """æ¼”ç¤ºæ ‡æ³¨è´¨é‡æ§åˆ¶"""
    tool = InteractiveAnnotationTool()
    
    print("\n=== æ ‡æ³¨è´¨é‡æ§åˆ¶æ¼”ç¤º ===")
    
    # æ¨¡æ‹Ÿå¤šä¸ªæ ‡æ³¨è®°å½•
    mock_annotations = [
        {
            'annotation_id': 'truck_001',
            'image_path': 'images/truck.jpg',
            'class_name': 'vehicle',
            'mask_area': 15000,
            'timestamp': '20240731_120000'
        },
        {
            'annotation_id': 'truck_002', 
            'image_path': 'images/truck.jpg',
            'class_name': 'vehicle',
            'mask_area': 18000,
            'timestamp': '20240731_120100'
        },
        {
            'annotation_id': 'dog_001',
            'image_path': 'images/dog.jpg',
            'class_name': 'animal',
            'mask_area': 12000,
            'timestamp': '20240731_120200'
        },
        {
            'annotation_id': 'person_001',
            'image_path': 'images/person.jpg',
            'class_name': 'person',
            'mask_area': 8000,
            'timestamp': '20240731_120300'
        }
    ]
    
    # åˆ›å»ºç»Ÿè®¡åˆ†æ
    stats = tool.create_annotation_statistics(mock_annotations)
    
    print("ğŸ“Š è´¨é‡æ§åˆ¶ç»Ÿè®¡:")
    print(f"  æ€»æ ‡æ³¨æ•°: {stats['total_annotations']}")
    print(f"  æ ‡æ³¨å›¾åƒæ•°: {stats['images_annotated']}")
    print(f"  å¹³å‡æ©ç é¢ç§¯: {stats['average_mask_area']:.0f} åƒç´ ")
    
    # è´¨é‡æ£€æŸ¥
    quality_issues = []
    
    # æ£€æŸ¥å¼‚å¸¸å¤§å°çš„æ©ç 
    for annotation in mock_annotations:
        area = annotation['mask_area']
        if area < 1000:
            quality_issues.append(f"æ©ç è¿‡å°: {annotation['annotation_id']} ({area} åƒç´ )")
        elif area > 50000:
            quality_issues.append(f"æ©ç è¿‡å¤§: {annotation['annotation_id']} ({area} åƒç´ )")
    
    # æ£€æŸ¥ç±»åˆ«ä¸å¹³è¡¡
    class_counts = stats['class_distribution']
    total_annotations = stats['total_annotations']
    
    for class_name, class_stats in class_counts.items():
        percentage = (class_stats['count'] / total_annotations) * 100
        if percentage < 10:
            quality_issues.append(f"ç±»åˆ«æ ·æœ¬ä¸è¶³: {class_name} (ä»… {percentage:.1f}%)")
        elif percentage > 70:
            quality_issues.append(f"ç±»åˆ«æ ·æœ¬è¿‡å¤š: {class_name} ({percentage:.1f}%)")
    
    print(f"\nâš ï¸  è´¨é‡é—®é¢˜æ£€æŸ¥:")
    if quality_issues:
        for issue in quality_issues:
            print(f"  - {issue}")
    else:
        print("  æœªå‘ç°æ˜æ˜¾è´¨é‡é—®é¢˜")
    
    # å¯è§†åŒ–è´¨é‡åˆ†æ
    tool.visualize_annotation_progress(mock_annotations, "annotation_quality_demo")

def demo_batch_annotation_workflow():
    """æ¼”ç¤ºæ‰¹é‡æ ‡æ³¨å·¥ä½œæµ"""
    print("\n=== æ‰¹é‡æ ‡æ³¨å·¥ä½œæµæ¼”ç¤º ===")
    
    # æ¨¡æ‹Ÿæ‰¹é‡æ ‡æ³¨åœºæ™¯
    image_list = [
        'images/truck.jpg',
        'images/dog.jpg', 
        'images/groceries.jpg'
    ]
    
    # æ£€æŸ¥å¯ç”¨å›¾åƒ
    available_images = [img for img in image_list if os.path.exists(img)]
    
    if not available_images:
        print("æ²¡æœ‰å¯ç”¨çš„æ¼”ç¤ºå›¾åƒ")
        return
    
    tool = InteractiveAnnotationTool()
    annotation_workflow = []
    
    for i, image_path in enumerate(available_images):
        print(f"\nå¤„ç†å›¾åƒ {i+1}/{len(available_images)}: {image_path}")
        
        try:
            tool.set_image(image_path)
            
            # æ¨¡æ‹Ÿè‡ªåŠ¨æ ‡æ³¨å»ºè®®ï¼ˆç®€åŒ–ç‰ˆï¼‰
            h, w = tool.current_image.shape[:2]
            suggested_points = [
                [w//2, h//2],  # ä¸­å¿ƒç‚¹
                [w//4, h//4],  # å·¦ä¸ŠåŒºåŸŸ
                [3*w//4, 3*h//4]  # å³ä¸‹åŒºåŸŸ
            ]
            
            workflow_step = {
                'image_path': image_path,
                'image_size': (h, w),
                'suggested_points': suggested_points,
                'annotation_status': 'pending'
            }
            
            # å¯¹æ¯ä¸ªå»ºè®®ç‚¹è¿›è¡Œåˆ†å‰²
            for j, point in enumerate(suggested_points):
                mask, score = tool.add_positive_point(point[0], point[1])
                if score > 0.8:  # é«˜è´¨é‡åˆ†å‰²
                    workflow_step[f'mask_{j}'] = {
                        'point': point,
                        'score': score,
                        'area': int(np.sum(mask)) if mask is not None else 0,
                        'quality': 'high' if score > 0.9 else 'medium'
                    }
            
            tool.clear_all_points()  # æ¸…ç†å‡†å¤‡ä¸‹ä¸€ä¸ªå›¾åƒ
            workflow_step['annotation_status'] = 'completed'
            annotation_workflow.append(workflow_step)
            
        except Exception as e:
            print(f"å¤„ç†å›¾åƒæ—¶å‡ºé”™: {e}")
            workflow_step['annotation_status'] = 'failed'
            workflow_step['error'] = str(e)
            annotation_workflow.append(workflow_step)
    
    # è¾“å‡ºå·¥ä½œæµæ€»ç»“
    print(f"\nğŸ“‹ æ‰¹é‡æ ‡æ³¨å·¥ä½œæµæ€»ç»“:")
    completed = sum(1 for step in annotation_workflow if step['annotation_status'] == 'completed')
    print(f"  å¤„ç†å›¾åƒæ€»æ•°: {len(annotation_workflow)}")
    print(f"  æˆåŠŸå¤„ç†: {completed}")
    print(f"  å¤„ç†å¤±è´¥: {len(annotation_workflow) - completed}")
    
    # ä¿å­˜å·¥ä½œæµè®°å½•
    workflow_file = "batch_annotation_workflow.json"
    with open(workflow_file, 'w', encoding='utf-8') as f:
        json.dump(annotation_workflow, f, indent=2, ensure_ascii=False)
    print(f"  å·¥ä½œæµè®°å½•å·²ä¿å­˜: {workflow_file}")

if __name__ == '__main__':
    print("=== SAMäº¤äº’å¼æ ‡æ³¨å·¥å…·æ¼”ç¤º ===")
    
    try:
        # æ¼”ç¤ºäº¤äº’å¼æ ‡æ³¨
        demo_interactive_annotation()
        
        # æ¼”ç¤ºè´¨é‡æ§åˆ¶
        demo_annotation_quality_control()
        
        # æ¼”ç¤ºæ‰¹é‡å·¥ä½œæµ
        demo_batch_annotation_workflow()
        
        print("\nâœ… äº¤äº’å¼æ ‡æ³¨å·¥å…·æ¼”ç¤ºå®Œæˆï¼")
        print("ğŸ’¡ åœ¨å®é™…æ ‡æ³¨é¡¹ç›®ä¸­ï¼Œå»ºè®®:")
        print("   1. å»ºç«‹æ ‡æ³¨è§„èŒƒå’Œè´¨é‡æ ‡å‡†")
        print("   2. å®šæœŸè¿›è¡Œæ ‡æ³¨è´¨é‡æ£€æŸ¥")
        print("   3. ä½¿ç”¨å¤šäººæ ‡æ³¨éªŒè¯é‡è¦æ ·æœ¬")
        print("   4. å»ºç«‹æ ‡æ³¨è¿›åº¦è·Ÿè¸ªç³»ç»Ÿ")
        print("   5. å¯¼å‡ºä¸ºå¸¸è§çš„æ•°æ®é›†æ ¼å¼(COCO, YOLOç­‰)")
        
    except Exception as e:
        print(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å’Œå›¾åƒæ–‡ä»¶å­˜åœ¨")
