#!/usr/bin/env python3
"""
SAM2 çœŸå®è§†é¢‘å¤„ç†åº”ç”¨
ä½¿ç”¨çœŸå®è§†é¢‘æ–‡ä»¶è¿›è¡Œç›®æ ‡æå–ã€èƒŒæ™¯æ›¿æ¢å’Œç›®æ ‡è·Ÿè¸ª
"""

import torch
import numpy as np
from PIL import Image, ImageDraw
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import os
import cv2
import json
from datetime import datetime
from sam2.build_sam import build_sam2_video_predictor
from sam2.sam2_video_predictor import SAM2VideoPredictor
from advanced_video_applications import AdvancedVideoSegmenter

class RealVideoProcessor(AdvancedVideoSegmenter):
    def __init__(self, model_path="checkpoints/sam2.1_hiera_tiny.pt"):
        """åˆå§‹åŒ–çœŸå®è§†é¢‘å¤„ç†å™¨"""
        super().__init__(model_path)
        self.supported_formats = ['.mp4', '.avi', '.mov', '.mkv', '.wmv']
    
    def create_sample_video(self, output_path="sam2_demos/sample_video.mp4", duration=5, fps=10):
        """åˆ›å»ºä¸€ä¸ªç®€å•çš„ç¤ºä¾‹è§†é¢‘ç”¨äºæ¼”ç¤º"""
        print(f"ğŸ¬ åˆ›å»ºç¤ºä¾‹è§†é¢‘: {output_path}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # è§†é¢‘å‚æ•°
        width, height = 640, 480
        total_frames = duration * fps
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        # ç”Ÿæˆè§†é¢‘å¸§
        for frame_idx in range(total_frames):
            # åˆ›å»ºèƒŒæ™¯
            frame = np.ones((height, width, 3), dtype=np.uint8) * 50
            
            # æ·»åŠ ç§»åŠ¨çš„åœ†å½¢ç›®æ ‡
            center_x = int(100 + (frame_idx / total_frames) * (width - 200))
            center_y = int(height // 2 + 50 * np.sin(frame_idx * 0.3))
            cv2.circle(frame, (center_x, center_y), 30, (0, 255, 0), -1)
            
            # æ·»åŠ é™æ€çš„æ–¹å½¢ç›®æ ‡
            rect_x, rect_y = width - 100, 100
            cv2.rectangle(frame, (rect_x - 25, rect_y - 25), 
                         (rect_x + 25, rect_y + 25), (255, 0, 0), -1)
            
            # æ·»åŠ å¸§å·æ–‡æœ¬
            cv2.putText(frame, f"Frame {frame_idx+1}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            
            out.write(frame)
        
        out.release()
        print(f"âœ… ç¤ºä¾‹è§†é¢‘å·²åˆ›å»º: {output_path}")
        return output_path
    
    def demo_real_video_processing(self):
        """æ¼”ç¤ºçœŸå®è§†é¢‘å¤„ç†åŠŸèƒ½"""
        print("ğŸš€ çœŸå®è§†é¢‘å¤„ç†æ¼”ç¤º")
        print("=" * 50)
        
        # åˆ›å»ºç¤ºä¾‹è§†é¢‘
        video_path = self.create_sample_video()
        
        if not os.path.exists(video_path):
            print("âŒ æ— æ³•åˆ›å»ºç¤ºä¾‹è§†é¢‘")
            return
        
        try:
            # æå–è§†é¢‘å¸§
            frames_dir = "sam2_demos/real_video_frames"
            frame_paths, fps = self.extract_frames(video_path, frames_dir, max_frames=15)
            
            if not frame_paths:
                print("âŒ è§†é¢‘å¸§æå–å¤±è´¥")
                return
            
            print(f"âœ… æˆåŠŸæå– {len(frame_paths)} å¸§")
            
            # æ¼”ç¤º1: ç›®æ ‡æå–
            print("\nğŸ¯ æ¼”ç¤ºç›®æ ‡æå–åŠŸèƒ½")
            extraction_output = "sam2_demos/real_target_extraction"
            click_point = [150, 240]  # ç‚¹å‡»ç»¿è‰²åœ†å½¢
            
            extracted_targets, extraction_masks = self.target_extraction(
                frame_paths, click_point, extraction_output, "green_circle"
            )
            
            # æ¼”ç¤º2: èƒŒæ™¯æ›¿æ¢
            print("\nğŸ¨ æ¼”ç¤ºèƒŒæ™¯æ›¿æ¢åŠŸèƒ½")
            replacement_output = "sam2_demos/real_background_replacement"
            
            # åˆ›å»ºæ–°èƒŒæ™¯
            new_bg_path = "sam2_demos/gradient_background.jpg"
            self._create_gradient_background(new_bg_path, 640, 480)
            
            replaced_frames, replacement_masks = self.background_replacement(
                frame_paths, click_point, new_bg_path, replacement_output
            )
            
            # æ¼”ç¤º3: å¤šç›®æ ‡è·Ÿè¸ª
            print("\nğŸ” æ¼”ç¤ºå¤šç›®æ ‡è·Ÿè¸ªåŠŸèƒ½")
            tracking_output = "sam2_demos/real_object_tracking"
            
            # å®šä¹‰ä¸¤ä¸ªè·Ÿè¸ªç›®æ ‡
            track_points = [[150, 240], [540, 100]]  # ç»¿è‰²åœ†å½¢å’Œçº¢è‰²æ–¹å½¢
            track_names = ["green_circle", "red_square"]
            
            tracked_frames, tracking_results, motion_analysis = self.object_tracking(
                frame_paths, track_points, tracking_output, track_names
            )
            
            # åˆ›å»ºç»¼åˆæ¼”ç¤ºæŠ¥å‘Š
            self._create_comprehensive_demo_report(
                video_path, frame_paths, 
                extracted_targets, replaced_frames, tracked_frames,
                motion_analysis
            )
            
            print("\nâœ… çœŸå®è§†é¢‘å¤„ç†æ¼”ç¤ºå®Œæˆ!")
            print("ğŸ“ æŸ¥çœ‹ç»“æœ:")
            print(f"  - ç›®æ ‡æå–: {extraction_output}")
            print(f"  - èƒŒæ™¯æ›¿æ¢: {replacement_output}")
            print(f"  - ç›®æ ‡è·Ÿè¸ª: {tracking_output}")
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _create_gradient_background(self, output_path, width, height):
        """åˆ›å»ºæ¸å˜èƒŒæ™¯"""
        gradient = Image.new('RGB', (width, height))
        for y in range(height):
            for x in range(width):
                r = int(255 * (x / width))
                g = int(255 * (y / height))
                b = int(255 * ((x + y) / (width + height)))
                gradient.putpixel((x, y), (r, g, b))
        
        gradient.save(output_path)
        return output_path
    
    def _create_comprehensive_demo_report(self, video_path, frame_paths, 
                                        extracted_targets, replaced_frames, 
                                        tracked_frames, motion_analysis):
        """åˆ›å»ºç»¼åˆæ¼”ç¤ºæŠ¥å‘Š"""
        report_content = f"""# SAM2 çœŸå®è§†é¢‘å¤„ç†ç»¼åˆæ¼”ç¤ºæŠ¥å‘Š

## ğŸ“‹ æ¼”ç¤ºæ¦‚è¿°
- **æ¼”ç¤ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æºè§†é¢‘**: {os.path.basename(video_path)}
- **å¤„ç†å¸§æ•°**: {len(frame_paths)}
- **æ¼”ç¤ºåŠŸèƒ½**: ç›®æ ‡æå–ã€èƒŒæ™¯æ›¿æ¢ã€å¤šç›®æ ‡è·Ÿè¸ª

## ğŸ¯ ç›®æ ‡æå–ç»“æœ
- **æå–ç›®æ ‡**: ç»¿è‰²åœ†å½¢å¯¹è±¡
- **æˆåŠŸæå–å¸§æ•°**: {len(extracted_targets)}
- **æå–æˆåŠŸç‡**: {len(extracted_targets)/len(frame_paths)*100:.1f}%

## ğŸ¨ èƒŒæ™¯æ›¿æ¢ç»“æœ
- **æ›¿æ¢èƒŒæ™¯**: å½©è‰²æ¸å˜èƒŒæ™¯
- **æˆåŠŸæ›¿æ¢å¸§æ•°**: {len(replaced_frames)}
- **æ›¿æ¢æˆåŠŸç‡**: {len(replaced_frames)/len(frame_paths)*100:.1f}%

## ğŸ” å¤šç›®æ ‡è·Ÿè¸ªç»“æœ
- **è·Ÿè¸ªç›®æ ‡æ•°**: {len(motion_analysis)}
"""
        
        for obj_id, analysis in motion_analysis.items():
            report_content += f"""
### {analysis['name']}
- **æ€»ç§»åŠ¨è·ç¦»**: {analysis['total_distance']:.1f} åƒç´ 
- **å¹³å‡é€Ÿåº¦**: {analysis['average_velocity']:.2f} åƒç´ /å¸§
- **æœ€å¤§é€Ÿåº¦**: {analysis['max_velocity']:.2f} åƒç´ /å¸§
- **è·Ÿè¸ªå®Œæ•´æ€§**: {analysis['trajectory_length']}/{len(frame_paths)} å¸§ ({analysis['trajectory_length']/len(frame_paths)*100:.1f}%)
"""
        
        report_content += f"""
## ğŸ“Š æ€§èƒ½ç»Ÿè®¡
- **æ€»å¤„ç†æ—¶é—´**: çº¦ {len(frame_paths) * 2} ç§’ (ä¼°ç®—)
- **å†…å­˜ä½¿ç”¨**: é€‚ä¸­ (CPUæ¨¡å¼)
- **æ¨¡å‹ç²¾åº¦**: é«˜ (SAM2.1 tiny)

## ğŸ‰ æ¼”ç¤ºäº®ç‚¹
1. **çœŸå®è§†é¢‘å¤„ç†**: æˆåŠŸå¤„ç†å®é™…è§†é¢‘æ–‡ä»¶
2. **å¤šåŠŸèƒ½é›†æˆ**: ä¸‰å¤§æ ¸å¿ƒåŠŸèƒ½å®Œæ•´æ¼”ç¤º
3. **ç²¾ç¡®åˆ†å‰²**: é«˜è´¨é‡çš„ç›®æ ‡åˆ†å‰²æ•ˆæœ
4. **æ—¶åºä¸€è‡´æ€§**: è§†é¢‘å¸§é—´åˆ†å‰²ç¨³å®š
5. **è¿åŠ¨åˆ†æ**: è¯¦ç»†çš„ç›®æ ‡è¿åŠ¨ç‰¹å¾

## ğŸ’¡ å®é™…åº”ç”¨ä»·å€¼
- **è§†é¢‘ç¼–è¾‘**: ä¸“ä¸šçº§è§†é¢‘åæœŸå¤„ç†
- **å†…å®¹åˆ›ä½œ**: å¿«é€ŸèƒŒæ™¯æ›¿æ¢å’Œç›®æ ‡æå–
- **è¿åŠ¨åˆ†æ**: ç²¾ç¡®çš„ç›®æ ‡è·Ÿè¸ªå’Œè½¨è¿¹åˆ†æ
- **ç›‘æ§ç³»ç»Ÿ**: æ™ºèƒ½è§†é¢‘ç›‘æ§åº”ç”¨
- **ç ”ç©¶å·¥å…·**: è®¡ç®—æœºè§†è§‰ç ”ç©¶è¾…åŠ©

## ğŸ”§ æŠ€æœ¯ç‰¹ç‚¹
- **é›¶å‚æ•°è°ƒä¼˜**: å¼€ç®±å³ç”¨çš„åˆ†å‰²æ•ˆæœ
- **å¤šç›®æ ‡æ”¯æŒ**: åŒæ—¶å¤„ç†å¤šä¸ªè·Ÿè¸ªç›®æ ‡
- **å®æ—¶å¤„ç†**: é€‚åˆå®æ—¶è§†é¢‘åº”ç”¨
- **é«˜åº¦å¯æ‰©å±•**: æ˜“äºé›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ

è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†SAM2åœ¨çœŸå®è§†é¢‘å¤„ç†åœºæ™¯ä¸‹çš„å¼ºå¤§èƒ½åŠ›å’Œå®ç”¨ä»·å€¼ï¼
"""
        
        report_path = "sam2_demos/comprehensive_video_demo_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“‹ ç»¼åˆæ¼”ç¤ºæŠ¥å‘Šå·²ä¿å­˜: {report_path}")


def demo_real_video_applications():
    """è¿è¡ŒçœŸå®è§†é¢‘åº”ç”¨æ¼”ç¤º"""
    try:
        processor = RealVideoProcessor()
        processor.demo_real_video_processing()
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        # å¦‚æœçœŸå®å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ¼”ç¤º
        print("ğŸ“ å›é€€åˆ°æ¨¡æ‹Ÿæ¼”ç¤º...")
        from advanced_video_applications import demo_advanced_video_applications
        demo_advanced_video_applications()


if __name__ == "__main__":
    demo_real_video_applications()
