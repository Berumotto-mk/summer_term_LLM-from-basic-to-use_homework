#!/usr/bin/env python3
"""
SAM2 ç®€åŒ–æ¼”ç¤ºè„šæœ¬ - ç”¨äºè°ƒè¯•
"""

import torch
import numpy as np
from PIL import Image
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
import os
import cv2

def test_sam2():
    print("ğŸš€ å¼€å§‹SAM2æ¼”ç¤ºæµ‹è¯•")
    print("=" * 40)
    
    # 1. åŸºç¡€æ£€æŸ¥
    print("ğŸ“‹ åŸºç¡€ç¯å¢ƒæ£€æŸ¥...")
    print(f"  - PyTorch: {torch.__version__}")
    print(f"  - CUDA: {torch.cuda.is_available()}")
    print(f"  - å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # 2. æ£€æŸ¥æ–‡ä»¶
    model_path = "checkpoints/sam2.1_hiera_tiny.pt"
    image_path = "notebooks/images/cars.jpg"
    config_name = "configs/sam2.1/sam2.1_hiera_t.yaml"
    
    print("\nğŸ“ æ–‡ä»¶æ£€æŸ¥...")
    print(f"  - æ¨¡å‹æƒé‡: {os.path.exists(model_path)} ({model_path})")
    print(f"  - ç¤ºä¾‹å›¾ç‰‡: {os.path.exists(image_path)} ({image_path})")
    print(f"  - é…ç½®æ–‡ä»¶: {os.path.exists('sam2/configs/sam2.1/sam2.1_hiera_t.yaml')} ({config_name})")
    
    if not all([os.path.exists(f) for f in [model_path, image_path]]) or not os.path.exists('sam2/configs/sam2.1/sam2.1_hiera_t.yaml'):
        print("âŒ å¿…è¦æ–‡ä»¶ç¼ºå¤±ï¼Œé€€å‡ºæ¼”ç¤º")
        return
    
    # 3. å¯¼å…¥SAM2
    print("\nğŸ“¦ å¯¼å…¥SAM2æ¨¡å—...")
    try:
        from sam2.build_sam import build_sam2
        from sam2.sam2_image_predictor import SAM2ImagePredictor
        print("âœ… SAM2æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ SAM2æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return
    
    # 4. åŠ è½½æ¨¡å‹
    print("\nğŸ”§ åŠ è½½SAM2æ¨¡å‹...")
    try:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"  - ä½¿ç”¨è®¾å¤‡: {device}")
        
        sam2_model = build_sam2("configs/sam2.1/sam2.1_hiera_t.yaml", model_path, device=device)
        predictor = SAM2ImagePredictor(sam2_model)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 5. åŠ è½½å›¾ç‰‡
    print("\nğŸ–¼ï¸  åŠ è½½å¹¶å¤„ç†å›¾ç‰‡...")
    try:
        image = Image.open(image_path).convert("RGB")
        image_array = np.array(image)
        print(f"  - å›¾ç‰‡å°ºå¯¸: {image_array.shape}")
        
        predictor.set_image(image_array)
        print("âœ… å›¾ç‰‡é¢„å¤„ç†å®Œæˆ")
    except Exception as e:
        print(f"âŒ å›¾ç‰‡å¤„ç†å¤±è´¥: {e}")
        return
    
    # 6. æ‰§è¡Œåˆ†å‰²
    print("\nğŸ¯ æ‰§è¡Œç‚¹å‡»åˆ†å‰²...")
    try:
        height, width = image_array.shape[:2]
        # ç‚¹å‡»å›¾ç‰‡ä¸­å¿ƒ
        input_point = np.array([[width//2, height//2]])
        input_label = np.array([1])
        
        print(f"  - ç‚¹å‡»ä½ç½®: ({width//2}, {height//2})")
        
        masks, scores, logits = predictor.predict(
            point_coords=input_point,
            point_labels=input_label,
            multimask_output=True,
        )
        
        print(f"âœ… åˆ†å‰²å®Œæˆ!")
        print(f"  - ç”Ÿæˆmaskæ•°é‡: {len(masks)}")
        print(f"  - å¾—åˆ†: {scores}")
        print(f"  - æœ€ä½³å¾—åˆ†: {scores.max():.3f}")
        
    except Exception as e:
        print(f"âŒ åˆ†å‰²å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 7. ä¿å­˜ç»“æœ
    print("\nğŸ’¾ ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
    try:
        best_mask = masks[scores.argmax()]
        
        # åˆ›å»ºæ›´è¯¦ç»†çš„å¯è§†åŒ–ç»“æœ
        fig = plt.figure(figsize=(18, 12))
        
        # 1. åŸå›¾
        plt.subplot(2, 3, 1)
        plt.imshow(image_array)
        plt.title("åŸå§‹å›¾ç‰‡", fontsize=14, fontweight='bold')
        plt.axis('off')
        
        # 2. åŸå›¾ + ç‚¹å‡»ç‚¹
        plt.subplot(2, 3, 2)
        plt.imshow(image_array)
        plt.plot(input_point[0, 0], input_point[0, 1], 'ro', markersize=12)
        plt.title("ç‚¹å‡»ç‚¹æ ‡è®°", fontsize=14, fontweight='bold')
        plt.axis('off')
        
        # 3. æœ€ä½³åˆ†å‰²mask
        plt.subplot(2, 3, 3)
        plt.imshow(best_mask, cmap='gray')
        plt.title(f"æœ€ä½³åˆ†å‰²mask (å¾—åˆ†: {scores.max():.3f})", fontsize=14, fontweight='bold')
        plt.axis('off')
        
        # 4. æ‰€æœ‰å€™é€‰maskçš„å¯¹æ¯”
        for i, (mask, score) in enumerate(zip(masks, scores)):
            plt.subplot(2, 3, 4 + i)
            plt.imshow(image_array)
            plt.imshow(mask, alpha=0.6, cmap='jet')
            plt.plot(input_point[0, 0], input_point[0, 1], 'ro', markersize=8)
            plt.title(f"å€™é€‰ {i+1} (å¾—åˆ†: {score:.3f})", fontsize=12)
            plt.axis('off')
        
        # ä¿å­˜å®Œæ•´çš„å¯è§†åŒ–ç»“æœ
        output_path = "sam2_demo_result_detailed.png"
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… è¯¦ç»†ç»“æœå·²ä¿å­˜: {output_path}")
        
        # åˆ›å»ºç®€åŒ–ç‰ˆæœ¬çš„å¯¹æ¯”å›¾
        fig, axes = plt.subplots(1, 2, figsize=(12, 6))
        
        # åŸå›¾ + ç‚¹å‡»ç‚¹
        axes[0].imshow(image_array)
        axes[0].plot(input_point[0, 0], input_point[0, 1], 'ro', markersize=10)
        axes[0].set_title("Original Image + Click Point", fontsize=14)
        axes[0].axis('off')
        
        # åˆ†å‰²ç»“æœ
        axes[1].imshow(image_array)
        axes[1].imshow(best_mask, alpha=0.5, cmap='jet')
        axes[1].plot(input_point[0, 0], input_point[0, 1], 'ro', markersize=10)
        axes[1].set_title(f"Segmentation Result (Score: {scores.max():.3f})", fontsize=14)
        axes[1].axis('off')
        
        # ä¿å­˜ç®€åŒ–ç‰ˆæœ¬
        simple_output_path = "sam2_demo_result.png"
        plt.tight_layout()
        plt.savefig(simple_output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… ç®€åŒ–ç»“æœå·²ä¿å­˜: {simple_output_path}")
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°ä¿¡æ¯
        if os.path.exists(output_path):
            size_kb = os.path.getsize(output_path) / 1024
            print(f"  - è¯¦ç»†ç‰ˆæœ¬æ–‡ä»¶å¤§å°: {size_kb:.1f} KB")
        
        if os.path.exists(simple_output_path):
            size_kb = os.path.getsize(simple_output_path) / 1024
            print(f"  - ç®€åŒ–ç‰ˆæœ¬æ–‡ä»¶å¤§å°: {size_kb:.1f} KB")
        
        # åˆ›å»ºmaskè½®å»“å¯è§†åŒ–
        print("\nğŸ¨ ç”Ÿæˆmaskè½®å»“å¯è§†åŒ–...")
        contour_image = image_array.copy()
        
        # å°†maskè½¬æ¢ä¸ºuint8æ ¼å¼
        mask_uint8 = (best_mask * 255).astype(np.uint8)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # åœ¨åŸå›¾ä¸Šç»˜åˆ¶è½®å»“
        cv2.drawContours(contour_image, contours, -1, (255, 0, 0), 3)  # çº¢è‰²è½®å»“
        
        # æ ‡è®°ç‚¹å‡»ç‚¹
        cv2.circle(contour_image, (int(input_point[0, 0]), int(input_point[0, 1])), 8, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹
        
        # ä¿å­˜è½®å»“ç‰ˆæœ¬
        contour_output_path = "sam2_demo_contour.png"
        cv2.imwrite(contour_output_path, cv2.cvtColor(contour_image, cv2.COLOR_RGB2BGR))
        
        print(f"âœ… è½®å»“ç»“æœå·²ä¿å­˜: {contour_output_path}")
        
        if os.path.exists(contour_output_path):
            size_kb = os.path.getsize(contour_output_path) / 1024
            print(f"  - è½®å»“ç‰ˆæœ¬æ–‡ä»¶å¤§å°: {size_kb:.1f} KB")
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    print("\n" + "=" * 40)
    print("ğŸ‰ SAM2æ¼”ç¤ºæµ‹è¯•å®Œæˆ!")
    print("\nğŸ“Š æ¼”ç¤ºç»“æœæ‘˜è¦:")
    print(f"  - è¾“å…¥å›¾ç‰‡: {image_path}")
    print(f"  - å›¾ç‰‡å°ºå¯¸: {width} Ã— {height} åƒç´ ")
    print(f"  - ç‚¹å‡»ä½ç½®: å›¾ç‰‡ä¸­å¿ƒ ({width//2}, {height//2})")
    print(f"  - ç”Ÿæˆmask: {len(masks)}ä¸ªå€™é€‰")
    print(f"  - å€™é€‰å¾—åˆ†: {[f'{s:.3f}' for s in scores]}")
    print(f"  - æœ€ä½³å¾—åˆ†: {scores.max():.3f}")
    print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - è¯¦ç»†ç‰ˆæœ¬: sam2_demo_result_detailed.png")
    print(f"  - ç®€åŒ–ç‰ˆæœ¬: sam2_demo_result.png")
    print(f"  - è½®å»“ç‰ˆæœ¬: sam2_demo_contour.png")
    print(f"\nğŸ’¡ è¯´æ˜:")
    print(f"  - è¯¦ç»†ç‰ˆæœ¬æ˜¾ç¤ºäº†æ‰€æœ‰å€™é€‰maskçš„å¯¹æ¯”")
    print(f"  - ç®€åŒ–ç‰ˆæœ¬é€‚åˆå¿«é€ŸæŸ¥çœ‹åˆ†å‰²æ•ˆæœ") 
    print(f"  - è½®å»“ç‰ˆæœ¬çªå‡ºæ˜¾ç¤ºäº†åˆ†å‰²è¾¹ç•Œ")

def display_results():
    """æ˜¾ç¤ºç”Ÿæˆçš„ç»“æœå›¾ç‰‡ä¿¡æ¯"""
    print("\n" + "=" * 50)
    print("ğŸ“¸ SAM2 åˆ†å‰²ç»“æœå±•ç¤º")
    print("=" * 50)
    
    result_files = [
        ("sam2_demo_result_detailed.png", "è¯¦ç»†ç‰ˆæœ¬ - æ˜¾ç¤ºæ‰€æœ‰å€™é€‰mask"),
        ("sam2_demo_result.png", "ç®€åŒ–ç‰ˆæœ¬ - åŸå›¾ä¸æœ€ä½³åˆ†å‰²å¯¹æ¯”"),
        ("sam2_demo_contour.png", "è½®å»“ç‰ˆæœ¬ - çªå‡ºæ˜¾ç¤ºåˆ†å‰²è¾¹ç•Œ")
    ]
    
    for filename, description in result_files:
        if os.path.exists(filename):
            size_kb = os.path.getsize(filename) / 1024
            print(f"âœ… {filename}")
            print(f"   {description}")
            print(f"   æ–‡ä»¶å¤§å°: {size_kb:.1f} KB")
            
            # è·å–å›¾ç‰‡å°ºå¯¸ä¿¡æ¯
            try:
                with Image.open(filename) as img:
                    print(f"   å›¾ç‰‡å°ºå¯¸: {img.width} Ã— {img.height} åƒç´ ")
            except:
                pass
            print()
        else:
            print(f"âŒ {filename} - æ–‡ä»¶ä¸å­˜åœ¨")
    
    print("ğŸ’¡ æŸ¥çœ‹æ–¹å¼:")
    print("  - åœ¨æ–‡ä»¶ç®¡ç†å™¨ä¸­åŒå‡»å›¾ç‰‡æ–‡ä»¶")
    print("  - ä½¿ç”¨ 'code <filename>' åœ¨VS Codeä¸­æŸ¥çœ‹")
    print("  - ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å›¾ç‰‡æŸ¥çœ‹å™¨")

def create_summary_report():
    """åˆ›å»ºæ¼”ç¤ºæ€»ç»“æŠ¥å‘Š"""
    print("\nğŸ“‹ åˆ›å»ºæ¼”ç¤ºæ€»ç»“æŠ¥å‘Š...")
    
    report_content = f"""# SAM2 æ¼”ç¤ºç»“æœæŠ¥å‘Š

## ğŸ”§ ç³»ç»Ÿé…ç½®
- **è¿è¡Œæ—¶é—´**: {os.popen('date').read().strip()}
- **Pythonç‰ˆæœ¬**: {torch.__version__.split('+')[0]}
- **PyTorchç‰ˆæœ¬**: {torch.__version__}
- **è¿è¡Œè®¾å¤‡**: {'GPU (CUDA)' if torch.cuda.is_available() else 'CPU'}
- **å·¥ä½œç›®å½•**: {os.getcwd()}

## ğŸ“Š æ¼”ç¤ºå‚æ•°
- **æ¨¡å‹**: sam2.1_hiera_tiny.pt (149MB)
- **é…ç½®**: configs/sam2.1/sam2.1_hiera_t.yaml
- **è¾“å…¥å›¾ç‰‡**: notebooks/images/cars.jpg
- **åˆ†å‰²æ–¹å¼**: å•ç‚¹ç‚¹å‡» (å›¾ç‰‡ä¸­å¿ƒ)

## ğŸ“ˆ åˆ†å‰²ç»“æœ
- **ç”Ÿæˆå€™é€‰**: 3ä¸ªmask
- **å€™é€‰å¾—åˆ†**: [è¯¦è§è¿è¡Œæ—¥å¿—]
- **æœ€ä½³å¾—åˆ†**: [è¯¦è§è¿è¡Œæ—¥å¿—]

## ğŸ“ è¾“å‡ºæ–‡ä»¶
1. **sam2_demo_result_detailed.png** - è¯¦ç»†å¯¹æ¯”ç‰ˆæœ¬
2. **sam2_demo_result.png** - ç®€åŒ–å¯¹æ¯”ç‰ˆæœ¬  
3. **sam2_demo_contour.png** - è½®å»“çªå‡ºç‰ˆæœ¬

## ğŸ¯ æ¼”ç¤ºæ•ˆæœ
SAM2æˆåŠŸå®Œæˆäº†ä»¥ä¸‹ä»»åŠ¡ï¼š
- âœ… æ¨¡å‹åŠ è½½å’Œåˆå§‹åŒ–
- âœ… å›¾åƒé¢„å¤„ç†å’Œç¼–ç 
- âœ… å•ç‚¹æç¤ºåˆ†å‰²
- âœ… å¤šå€™é€‰maskç”Ÿæˆ
- âœ… ç»“æœå¯è§†åŒ–å’Œä¿å­˜

## ğŸ“ æŠ€æœ¯è¯´æ˜
SAM2 (Segment Anything Model 2) å±•ç¤ºäº†å…ˆè¿›çš„é›¶æ ·æœ¬åˆ†å‰²èƒ½åŠ›ï¼š
- ä»…éœ€ä¸€ä¸ªç‚¹å‡»å³å¯æ™ºèƒ½è¯†åˆ«å¯¹è±¡
- ç”Ÿæˆå¤šä¸ªå€™é€‰ç»“æœä¾›é€‰æ‹©
- æä¾›ç½®ä¿¡åº¦è¯„åˆ†
- æ”¯æŒå®æ—¶äº¤äº’å¼åˆ†å‰²

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {os.popen('date').read().strip()}*
"""
    
    with open("SAM2_Demo_Report.md", "w", encoding="utf-8") as f:
        f.write(report_content)
    
    print("âœ… æŠ¥å‘Šå·²ä¿å­˜: SAM2_Demo_Report.md")

if __name__ == "__main__":
    # è¿è¡Œä¸»æ¼”ç¤º
    test_sam2()
    
    # æ˜¾ç¤ºç»“æœæ–‡ä»¶ä¿¡æ¯
    display_results()
    
    # åˆ›å»ºæ€»ç»“æŠ¥å‘Š
    create_summary_report()
    
    print("\nğŸ‰ SAM2å®Œæ•´æ¼”ç¤ºç»“æŸï¼")
    print("è¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶ä»¥æŸ¥çœ‹åˆ†å‰²æ•ˆæœã€‚")
